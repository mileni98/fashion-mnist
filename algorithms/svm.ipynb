{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM - Support Vector Machine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from PIL import Image\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from ipynb.fs.defs.additional_metrics import *\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining functions that will perform .fit() and .predict() while calculating execution time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svc_fit_with_time(svc, X_trainCV, y_trainCV, time_fit_tmp):\n",
    "    start = time.time()     \n",
    "    svc.fit(X_trainCV, y_trainCV)\n",
    "    time_fit_tmp.append(time.time()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svc_predict_with_time(svc, X_testCV, time_pred_tmp):\n",
    "    start = time.time()\n",
    "    y_pred = svc.predict(X_testCV)\n",
    "    time_pred_tmp.append(time.time()-start)\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trained on 30% samples of the original training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"../datasets/fashion-mnist_train.csv\")\n",
    "X_train = train_data.iloc[:,1:]\n",
    "y_train = train_data.iloc[:,0]\n",
    "\n",
    "test_data = pd.read_csv(\"../datasets/fashion-mnist_test.csv\")\n",
    "X_test = test_data.iloc[:,1:]\n",
    "y_test = test_data.iloc[:,0]\n",
    "\n",
    "X_train_std = (X_train - X_train.mean())/X_train.std()\n",
    "X_test_std = (X_test - X_test.mean())/X_test.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_30, X_test_30, y_train_30, y_test_30 = train_test_split(X_train_std, y_train, test_size=0.7, stratify=y_train, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = StratifiedKFold(n_splits = 5, shuffle = True, random_state = 42)\n",
    "acc = []\n",
    "i, p_val, best_acc, best_c = 0, 0, 0, 0\n",
    "best_k, best_g = '', ''\n",
    "\n",
    "for c in [0.1, 0.5, 1, 3, 5, 6, 7, 8, 9, 10, 13, 15, 20, 50]:\n",
    "    for k in [\"linear\", \"poly\", \"rbf\", \"sigmoid\"]:\n",
    "        for g in [\"scale\", \"auto\"]:\n",
    "            \n",
    "            acc_tmp, time_fit_tmp, time_pred_tmp = [], [], []\n",
    " \n",
    "            indexes = kf.split(X_train_30, y_train_30)\n",
    "\n",
    "            for train_index, test_index in indexes:\n",
    "\n",
    "                X_trainCV1 = X_train_30.iloc[train_index,:]\n",
    "                y_trainCV1 = y_train_30.iloc[train_index]\n",
    "                X_testCV1 = X_train_30.iloc[test_index,:]\n",
    "                y_testCV1 = y_train_30.iloc[test_index]\n",
    "\n",
    "                classifier1 = SVC(C = c, kernel = k, gamma = g)\n",
    "                \n",
    "                svc_fit_with_time(classifier1, X_trainCV1, y_trainCV1, time_fit_tmp)\n",
    "                y_pred1 = svc_predict_with_time(classifier1, X_testCV1, time_pred_tmp)\n",
    "\n",
    "                c1 = confusion_matrix(y_testCV1, y_pred1)\n",
    "                acc_tmp.append(np.trace(c1)/sum(sum(c1)))\n",
    "            \n",
    "            print(f\"{i+1}. C = {c}, k = {k}, g = {g}, Average accuracy: {np.mean(acc_tmp):.6f} | Average fit time: {np.mean(time_fit_tmp):.6f}s | Average predict time: {np.mean(time_pred_tmp):.6f}s\")\n",
    "            acc.append(np.mean(acc_tmp))\n",
    "            i += 1\n",
    "\n",
    "            if np.mean(acc_tmp) > best_acc:\n",
    "                best_acc = np.mean(acc_tmp)\n",
    "                best_c, best_k, best_g = c, k, g\n",
    "            \n",
    "    print('')\n",
    "\n",
    "print('-------------------')\n",
    "print('Best accuracy is in iteration number:', np.argmax(acc) + 1, ' | for c =', best_c, ', k =', best_k, ', g =', best_g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checking if other parameters speed up the process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "best_time_fit = 99999\n",
    "best_dfs, best_s = '', False\n",
    "\n",
    "for dfs in [\"ovo\", \"ovr\"]:\n",
    "    for s in [True, False]:\n",
    "\n",
    "        acc_tmp, time_fit_tmp, time_pred_tmp = [], [], []\n",
    "            \n",
    "        indexes = kf.split(X_train_30, y_train_30)\n",
    "\n",
    "        for train_index, test_index in indexes:\n",
    "\n",
    "            X_trainCV1 = X_train_30.iloc[train_index,:]\n",
    "            y_trainCV1 = y_train_30.iloc[train_index]\n",
    "            X_testCV1 = X_train_30.iloc[test_index,:]\n",
    "            y_testCV1 = y_train_30.iloc[test_index]\n",
    "\n",
    "            classifier1 = SVC(C = best_c, kernel = best_k, gamma = best_g, shrinking = s, decision_function_shape = dfs)\n",
    "                \n",
    "            svc_fit_with_time(classifier1, X_trainCV1, y_trainCV1, time_fit_tmp)\n",
    "            y_pred1 = svc_predict_with_time(classifier1, X_testCV1, time_pred_tmp)\n",
    "\n",
    "            c1 = confusion_matrix(y_testCV1, y_pred1)\n",
    "            acc_tmp.append(np.trace(c1)/sum(sum(c1)))\n",
    "        \n",
    "        print(f\"dfs = {dfs}, s = {s} Average accuracy: {np.mean(acc_tmp):.6f} | Average fit time: {np.mean(time_fit_tmp):.6f}s | Average predict time: {np.mean(time_pred_tmp):.6f}s\")\n",
    "         \n",
    "        if np.mean(time_fit_tmp) < best_time_fit:\n",
    "            best_time_fit = np.mean(time_fit_tmp)\n",
    "            best_dfs, best_s = dfs, s\n",
    "\n",
    "print('')    \n",
    "print('-------------------')\n",
    "print(f'Best accuracy is for dfs = {best_dfs}, s = {best_s}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training on 30% training samples, test on test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier1 = SVC(C = best_c, kernel = best_k, gamma = best_g, decision_function_shape = best_dfs, shrinking = best_s)\n",
    "\n",
    "start1 = time.time()\n",
    "classifier1.fit(X_train_30, y_train_30)\n",
    "fit_time = time.time() - start1\n",
    "\n",
    "start2 = time.time()\n",
    "y_pred2 = classifier1.predict(X_test_std)\n",
    "pred_time = time.time() - start2\n",
    "\n",
    "c2 = confusion_matrix(y_test, y_pred2, labels=[0,1,2,3,4,5,6,7,8,9])\n",
    "    \n",
    "print(f\"Accuracy: {np.trace(c2)/sum(sum(c2)):.6f} | Average fit time: {fit_time:.6f}s | Average predict time: {pred_time:.6f}s\")\n",
    "print('-------------------')\n",
    "print('SVC parameters: c = ', best_c, ', k = ', best_k, ', g = ', best_g, ', dfs = ', best_dfs, ', s = ', best_s, sep='')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trained on 100% samples of the original training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"../datasets/fashion-mnist_train.csv\")\n",
    "X_train = train_data.iloc[:,1:]\n",
    "y_train = train_data.iloc[:,0]\n",
    "\n",
    "test_data = pd.read_csv(\"../datasets/fashion-mnist_test.csv\")\n",
    "X_test = test_data.iloc[:,1:]\n",
    "y_test = test_data.iloc[:,0]\n",
    "\n",
    "X_train_std = (X_train - X_train.mean()) / X_train.std()\n",
    "X_test_std = (X_test - X_test.mean()) / X_test.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "acc, acc_tmp, time_fit_tmp, time_pred_tmp = [], [], [], []\n",
    "     \n",
    "indexes = kf.split(X_train, y_train)\n",
    "\n",
    "for train_index, test_index in indexes:\n",
    "    \n",
    "    X_trainCV2 = X_train_std.iloc[train_index,:]\n",
    "    y_trainCV2 = y_train.iloc[train_index]\n",
    "    X_testCV2 = X_train_std.iloc[test_index,:]\n",
    "    y_testCV2 = y_train.iloc[test_index]\n",
    "\n",
    "    classifier2 = SVC(C = best_c, kernel = best_k, gamma = best_g, decision_function_shape = best_dfs, shrinking = best_s)\n",
    "                \n",
    "    svc_fit_with_time(classifier2, X_trainCV2, y_trainCV2, time_fit_tmp)\n",
    "    y_pred3 = svc_predict_with_time(classifier2, X_testCV2, time_pred_tmp)\n",
    "\n",
    "    c3 = confusion_matrix(y_testCV2, y_pred3)\n",
    "    acc_tmp.append(np.trace(c3)/sum(sum(c3)))\n",
    "\n",
    "    print(f\"        Accuracy: {np.trace(c3)/sum(sum(c3)):.6f} | Fit time: {time_fit_tmp[-1]:.6f}s | Predict time: {time_pred_tmp[-1]:.6f}s\")\n",
    "\n",
    "print(\"\")    \n",
    "print('-------------------')\n",
    "print(f\"Average accuracy: {np.mean(acc_tmp):.6f} | Average fit time: {np.mean(time_fit_tmp):.6f}s | Average predict time: {np.mean(time_pred_tmp):.6f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Training on 100% training samples, test on test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier2 = SVC(C = best_c, kernel = best_k, gamma = best_g, decision_function_shape = best_dfs, shrinking = best_s)\n",
    "\n",
    "start1 = time.time()\n",
    "classifier2.fit(X_train_std, y_train)\n",
    "fit_time = time.time() - start1\n",
    "\n",
    "start2 = time.time()\n",
    "y_pred4 = classifier2.predict(X_test_std)\n",
    "pred_time = time.time() - start2\n",
    "\n",
    "c4 = confusion_matrix(y_test, y_pred4, labels=[0,1,2,3,4,5,6,7,8,9])\n",
    "    \n",
    "print(f\"Accuracy: {np.trace(c4)/sum(sum(c4)):.6f} | Average fit time: {fit_time:.6f}s | Average predict time: {pred_time:.6f}s\")\n",
    "print('-------------------')\n",
    "print('SVC parameters: c = ', best_c, ', k = ', best_k, ', g = ', best_g, ', dfs = ', best_dfs, ', s = ', best_s, sep='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trained on 100% samples with PCA reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"../datasets/fashion-mnist_train.csv\")\n",
    "X_train = train_data.iloc[:,1:]\n",
    "y_train = train_data.iloc[:,0]\n",
    "\n",
    "test_data = pd.read_csv(\"../datasets/fashion-mnist_test.csv\")\n",
    "X_test = test_data.iloc[:,1:]\n",
    "y_test = test_data.iloc[:,0]\n",
    "\n",
    "X_train_std = (X_train - X_train.mean()) / X_train.std()\n",
    "X_test_std = (X_test - X_test.mean()) / X_test.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "kf = StratifiedKFold(n_splits = 5, shuffle = True, random_state = 42)\n",
    "acc = []\n",
    "i, p_val, best_acc, best_c, best_pca = 0, 0, 0, 0, 0\n",
    "best_k = ''\n",
    "best_g = 'scale'\n",
    "\n",
    "for c in [0.1, 0.5, 1, 3, 5, 6, 7, 8, 9, 10, 13, 15, 20]:\n",
    "    for k in [\"linear\", \"poly\", \"rbf\"]:\n",
    "        for pc in [0.8, 0.85, 0.9, 0.95]:\n",
    "    \n",
    "            acc_tmp, time_fit_tmp, time_pred_tmp = [], [], []\n",
    "\n",
    "            indexes = kf.split(X_train, y_train)\n",
    "\n",
    "            for train_index, test_index in indexes:\n",
    "\n",
    "                X_trainCV3 = X_train_std.iloc[train_index,:]\n",
    "                y_trainCV3 = y_train.iloc[train_index]\n",
    "                X_testCV3 = X_train_std.iloc[test_index,:]\n",
    "                y_testCV3 = y_train.iloc[test_index]\n",
    "\n",
    "                pca = PCA(n_components=pc)\n",
    "                pca.fit(X_trainCV3)\n",
    "                X_train_r = pca.transform(X_trainCV3)\n",
    "                X_test_r = pca.transform(X_testCV3)\n",
    "\n",
    "                classifier3 = SVC(C = c, kernel = k, gamma = best_g)\n",
    "                \n",
    "                svc_fit_with_time(classifier3, X_trainCV3, y_trainCV3, time_fit_tmp)\n",
    "                y_pred5 = svc_predict_with_time(classifier3, X_testCV3, time_pred_tmp)\n",
    "\n",
    "                c5 = confusion_matrix(y_testCV3, y_pred5)\n",
    "                acc_tmp.append(np.trace(c5)/sum(sum(c5)))\n",
    "\n",
    "            print(f\"{i+1}. pca = {pc}, C = {c}, k = {k}, g = scale, Average accuracy: {np.mean(acc_tmp):.6f} | Average fit time: {np.mean(time_fit_tmp):.6f}s | Average predict time: {np.mean(time_pred_tmp):.6f}s\")\n",
    "            acc.append(np.mean(acc_tmp))\n",
    "            i += 1\n",
    "\n",
    "            if np.mean(acc_tmp) > best_acc:\n",
    "                best_acc = np.mean(acc_tmp)\n",
    "                best_c, best_k, best_pca = c, k, pc\n",
    "            \n",
    "    print('')\n",
    "\n",
    "print('-------------------')\n",
    "print('Best accuracy is in iteration number:', np.argmax(acc) + 1, ' | for c =', best_c, ', k =', best_k, ', g = scale, pca =', best_pca)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checking if other parameters speed up the process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "best_time_fit = 99999\n",
    "best_dfs, best_s = '', False\n",
    "\n",
    "for dfs in [\"ovo\", \"ovr\"]:\n",
    "    for s in [True, False]:\n",
    "    \n",
    "        acc_tmp, time_fit_tmp, time_pred_tmp = [], [], []\n",
    "\n",
    "        indexes = kf.split(X_train, y_train)\n",
    "\n",
    "        for train_index, test_index in indexes:\n",
    "\n",
    "            X_trainCV3 = X_train_std.iloc[train_index,:]\n",
    "            y_trainCV3 = y_train.iloc[train_index]\n",
    "            X_testCV3 = X_train_std.iloc[test_index,:]\n",
    "            y_testCV3 = y_train.iloc[test_index]\n",
    "\n",
    "            pca = PCA(n_components = best_pca)\n",
    "            pca.fit(X_trainCV3)\n",
    "            X_train_r = pca.transform(X_trainCV3)\n",
    "            X_test_r = pca.transform(X_testCV3)\n",
    "\n",
    "            classifier3 = SVC(C = best_c, kernel = best_k, gamma = best_g, shrinking = s, decision_function_shape = dfs)\n",
    "                \n",
    "            svc_fit_with_time(classifier3, X_train_r, y_trainCV3, time_fit_tmp)\n",
    "            y_pred5 = svc_predict_with_time(classifier3, X_test_r, time_pred_tmp)\n",
    "\n",
    "            c5 = confusion_matrix(y_testCV3, y_pred5)\n",
    "            acc_tmp.append(np.trace(c5)/sum(sum(c5)))\n",
    "        \n",
    "        print(f\"dfs = {dfs}, s = {s} Average accuracy: {np.mean(acc_tmp):.6f} | Average fit time: {np.mean(time_fit_tmp):.6f}s | Average predict time: {np.mean(time_pred_tmp):.6f}s\")\n",
    "         \n",
    "        if np.mean(time_fit_tmp) < best_time_fit:\n",
    "            best_time_fit = np.mean(time_fit_tmp)\n",
    "            best_dfs, best_s = dfs, s\n",
    "\n",
    "print('')    \n",
    "print('-------------------')\n",
    "print(f'Best accuracy is for dfs = {best_dfs}, s = {best_s}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Training on 100% training samples with PCA reduction, test on test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=best_pca)\n",
    "pca.fit(X_train_std)\n",
    "X_train_r = pca.transform(X_train_std)\n",
    "X_test_r = pca.transform(X_test_std)\n",
    "\n",
    "\n",
    "classifier3 = SVC(C = best_c, kernel = best_k, gamma = best_g, shrinking = best_s, decision_function_shape = best_dfs)\n",
    "\n",
    "start1 = time.time()\n",
    "classifier3.fit(X_train_r, y_train) \n",
    "fit_time = time.time() - start1\n",
    "\n",
    "start2 = time.time()\n",
    "y_pred6 = classifier3.predict(X_test_r)\n",
    "pred_time = time.time() - start2\n",
    "\n",
    "c6 = confusion_matrix(y_test, y_pred6, labels=[0,1,2,3,4,5,6,7,8,9])\n",
    "    \n",
    "print(f\"Accuracy: {np.trace(c6)/sum(sum(c6)):.6f} | Average fit time: {fit_time:.6f}s | Average predict time: {pred_time:.6f}s\")\n",
    "print('-------------------')\n",
    "print('SVC parameters: c = ', best_c, ', k = ', best_k, ', g = ', best_g, ', dfs = ', best_dfs, ', s = ', best_s, ', pca = ', best_pca, sep='')            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion matrix\n",
    "print(c6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(accuracy_per_class(c6, y_test.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sensitivity_per_class(c6, y_test.unique()))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examples of wrong classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_np = y_pred6\n",
    "print(type(y_pred6))\n",
    "\n",
    "y_test_np = y_test.to_numpy()\n",
    "print(type(y_test_np))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def differences(a,b):\n",
    "    list = []\n",
    "    for j in range(len(a)):\n",
    "        if b[j] != a[j]:\n",
    "            list = list + [j]        \n",
    "    arrayIndexes = np.asarray(list)\n",
    "    return arrayIndexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff = differences(y_pred_np, y_test_np)\n",
    "print(diff[:9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,8))\n",
    "\n",
    "for j in range(0,9):  \n",
    "    plt.subplot(3,3,j+1)    \n",
    "    arr = X_test.iloc[diff[j+100],:].to_numpy()\n",
    "    \n",
    "    arr = arr.reshape(28,28)\n",
    "    arr = arr.astype(np.uint8)\n",
    "    img = Image.fromarray(arr, \"L\")\n",
    "    \n",
    "    plt.imshow(img, cmap = 'gray')\n",
    "    plt.title(f\"Predicted {y_pred_np[diff[j+100]]}, Real {y_test_np[diff[j+100]]}\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
