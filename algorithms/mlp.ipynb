{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP - Multilayer Perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from PIL import Image\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from ipynb.fs.defs.Additional_metrics import *"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining functions that will perform .fit() and .predict() while calculating execution time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlp_fit_with_time(mlp, X_trainCV, y_trainCV, time_fit_tmp):\n",
    "    start = time.time()     \n",
    "    mlp.fit(X_trainCV, y_trainCV)\n",
    "    time_fit_tmp.append(time.time()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlp_predict_with_time(mlp, X_testCV, time_pred_tmp):\n",
    "    start = time.time()\n",
    "    y_pred = mlp.predict(X_testCV)\n",
    "    time_pred_tmp.append(time.time()-start)\n",
    "    return y_pred"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting touple values for number of neurons in layers, where every layer has same or same neurons than the previous layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools \n",
    "\n",
    "x = [128, 96, 64, 32, 16] \n",
    "hd_list = list(itertools.combinations(x,3)) + list(itertools.combinations(x,2)) + [(128,128,128), (96,96,96), (64,64,64), (32,32,32), (128,128), (96,96), (64,64)]\n",
    "print(hd_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trained on 30% samples of the original training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"../datasets/fashion-mnist_train.csv\")\n",
    "X_train = train_data.iloc[:,1:]\n",
    "y_train = train_data.iloc[:,0]\n",
    "\n",
    "test_data = pd.read_csv(\"../datasets/fashion-mnist_test.csv\")\n",
    "X_test = test_data.iloc[:,1:]\n",
    "y_test = test_data.iloc[:,0]\n",
    "\n",
    "X_train_std = (X_train - X_train.mean()) / X_train.std()\n",
    "X_test_std = (X_test - X_test.mean()) / X_test.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_30, X_test_30, y_train_30, y_test_30 = train_test_split(X_train_std, y_train, test_size=0.7, stratify=y_train, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "kf = StratifiedKFold(n_splits = 5, shuffle = True, random_state = 42)\n",
    "acc = []\n",
    "i, best_acc, best_bs  = 0, 0, 0\n",
    "best_a, best_s = '', ''\n",
    "best_hd = ()\n",
    "\n",
    "for hd in hd_list:\n",
    "    for a in [\"logistic\", \"tanh\", \"relu\"]:\n",
    "        # \"lbfgs\" isn't good for big databases\n",
    "        for s in [\"sgd\", \"adam\"]:\n",
    "            for bs in [64]:\n",
    "\n",
    "                acc_tmp, time_fit_tmp, time_pred_tmp = [], [], []\n",
    "                \n",
    "                indexes = kf.split(X_train_30, y_train_30)\n",
    "\n",
    "                for train_index, test_index in indexes:\n",
    "\n",
    "                    X_trainCV1 = X_train_30.iloc[train_index,:]\n",
    "                    y_trainCV1 = y_train_30.iloc[train_index]\n",
    "                    X_testCV1 = X_train_30.iloc[test_index,:]\n",
    "                    y_testCV1 = y_train_30.iloc[test_index]\n",
    "\n",
    "                    classifier1 = MLPClassifier(hidden_layer_sizes = hd, activation = a,\n",
    "                                                    solver = s, batch_size = bs, learning_rate = \"constant\", \n",
    "                                                    learning_rate_init = 0.001, max_iter = 100, shuffle = True,\n",
    "                                                    random_state = 42, early_stopping = True, n_iter_no_change = 10,\n",
    "                                                    validation_fraction = 0.1, verbose = False)\n",
    "                    \n",
    "                    mlp_fit_with_time(classifier1, X_trainCV1.values, y_trainCV1.values, time_fit_tmp)\n",
    "                    y_pred1 = mlp_predict_with_time(classifier1, X_testCV1.values, time_pred_tmp)\n",
    "\n",
    "                    c1 = confusion_matrix(y_testCV1, y_pred1)\n",
    "                    acc_tmp.append(np.trace(c1)/sum(sum(c1)))\n",
    "\n",
    "                print(f\"{i+1}. Hd = {hd}, a = {a}, s = {s}, bs = {bs}, Average accuracy: {np.mean(acc_tmp):.6f} | Average fit time: {np.mean(time_fit_tmp):.6f}s | Average predict time: {np.mean(time_pred_tmp):.6f}s\")\n",
    "                acc.append(np.mean(acc_tmp))\n",
    "                i += 1\n",
    "\n",
    "                if np.mean(acc_tmp) > best_acc:\n",
    "                    best_acc = np.mean(acc_tmp)\n",
    "                    best_hd, best_a, best_s, best_bs = hd, a, s, bs\n",
    "            \n",
    "    print('')\n",
    "      \n",
    "print('-------------------')\n",
    "print('Best accuracy is in iteration number: ', np.argmax(acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training on 30% training samples, test on test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier1 = MLPClassifier(hidden_layer_sizes = best_hd, activation = best_a,\n",
    "                        solver = best_s, batch_size = best_bs, learning_rate = \"constant\", \n",
    "                            learning_rate_init = 0.001, max_iter = 100, shuffle = True,\n",
    "                            random_state = 42, early_stopping = True, n_iter_no_change = 10,\n",
    "                            validation_fraction = 0.1, verbose = False)\n",
    "\n",
    "start1 = time.time()\n",
    "classifier1.fit(X_train_30.values, y_train_30.values)\n",
    "fit_time = time.time() - start1\n",
    "\n",
    "start2 = time.time()\n",
    "y_pred2 = classifier1.predict(X_test_std.values)\n",
    "pred_time = time.time() - start2\n",
    "\n",
    "c2 = confusion_matrix(y_test, y_pred2, labels=[0,1,2,3,4,5,6,7,8,9])\n",
    "\n",
    "print(f\"Accuracy: {np.trace(c2)/sum(sum(c2)):.6f} | Average fit time: {fit_time:.6f}s | Average predict time: {pred_time:.6f}s\")\n",
    "print('-------------------')\n",
    "print('MLP parameters: hd = ', best_hd, ', a = ', best_a, ', s = ', best_s, ', bs = ', best_bs, sep='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trained on 100% samples of the original training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"../datasets/fashion-mnist_train.csv\")\n",
    "X_train = train_data.iloc[:,1:]\n",
    "y_train = train_data.iloc[:,0]\n",
    "\n",
    "test_data = pd.read_csv(\"../datasets/fashion-mnist_test.csv\")\n",
    "X_test = test_data.iloc[:,1:]\n",
    "y_test = test_data.iloc[:,0]\n",
    "\n",
    "X_train_std = (X_train - X_train.mean()) / X_train.std()\n",
    "X_test_std = (X_test - X_test.mean()) / X_test.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "acc, acc_tmp, time_fit_tmp, time_pred_tmp = [], [], [], []\n",
    "\n",
    "indexes = kf.split(X_train, y_train)\n",
    "        \n",
    "for train_index, test_index in indexes:\n",
    "    \n",
    "    X_trainCV2 = X_train_std.iloc[train_index,:]\n",
    "    y_trainCV2 = y_train.iloc[train_index]\n",
    "    X_testCV2 = X_train_std.iloc[test_index,:]\n",
    "    y_testCV2 = y_train.iloc[test_index]\n",
    "                   \n",
    "    classifier2 = MLPClassifier(hidden_layer_sizes = best_hd, activation = best_a,\n",
    "                            solver = best_s, batch_size = best_bs, learning_rate = \"constant\", \n",
    "                            learning_rate_init = 0.001, max_iter = 100, shuffle = True,\n",
    "                            random_state = 42, early_stopping = True, n_iter_no_change = 10,\n",
    "                            validation_fraction = 0.1, verbose = False)\n",
    "    \n",
    "    mlp_fit_with_time(classifier2, X_trainCV2.values, y_trainCV2.values, time_fit_tmp)\n",
    "    y_pred3 = mlp_predict_with_time(classifier2, X_testCV2.values, time_pred_tmp)\n",
    "\n",
    "    c3 = confusion_matrix(y_testCV2, y_pred3)\n",
    "    acc_tmp.append(np.trace(c3)/sum(sum(c3)))\n",
    "\n",
    "    print(f\"        Accuracy: {np.trace(c3)/sum(sum(c3)):.6f} | Fit time: {time_fit_tmp[-1]:.6f}s | Predict time: {time_pred_tmp[-1]:.6f}s\")\n",
    "\n",
    "print(\"\")    \n",
    "print('-------------------')\n",
    "print(f\"Average accuracy: {np.mean(acc_tmp):.6f} | Average fit time: {np.mean(time_fit_tmp):.6f}s | Average predict time: {np.mean(time_pred_tmp):.6f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Training on 100% training samples, test on test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier2 = MLPClassifier(hidden_layer_sizes = best_hd, activation = best_a,\n",
    "                            solver = best_s, batch_size = best_bs, learning_rate = \"constant\", \n",
    "                            learning_rate_init = 0.001, max_iter = 100, shuffle = True,\n",
    "                            random_state = 42, early_stopping = True, n_iter_no_change = 10,\n",
    "                            validation_fraction = 0.1, verbose = False)\n",
    "\n",
    "start1 = time.time()\n",
    "classifier2.fit(X_train_std.values, y_train.values)\n",
    "fit_time = time.time() - start1\n",
    "\n",
    "start2 = time.time()\n",
    "y_pred4 = classifier2.predict(X_test_std.values)\n",
    "pred_time = time.time() - start2\n",
    "\n",
    "c4 = confusion_matrix(y_test, y_pred4, labels=[0,1,2,3,4,5,6,7,8,9])  \n",
    "\n",
    "print(f\"Accuracy: {np.trace(c4)/sum(sum(c4)):.6f} | Average fit time: {fit_time:.6f}s | Average predict time: {pred_time:.6f}s\")\n",
    "print('-------------------')\n",
    "print('MLP parameters: hd = ', best_hd, ', a = ', best_a, ', s = ', best_s, ', bs = ', best_bs, sep='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trained on 100% samples with PCA reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"../datasets/fashion-mnist_train.csv\")\n",
    "X_train = train_data.iloc[:,1:]\n",
    "y_train = train_data.iloc[:,0]\n",
    "\n",
    "test_data = pd.read_csv(\"../datasets/fashion-mnist_test.csv\")\n",
    "X_test = test_data.iloc[:,1:]\n",
    "y_test = test_data.iloc[:,0]\n",
    "\n",
    "X_train_std = (X_train - X_train.mean()) / X_train.std()\n",
    "X_test_std = (X_test - X_test.mean()) / X_test.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "acc = []\n",
    "i, best_acc, best_pca = 0, 0, 0, 0\n",
    "best_a, best_s = '', ''\n",
    "best_hd = ()\n",
    "\n",
    "for hd in hd_list:\n",
    "    for a in [\"logistic\", \"tanh\", \"relu\"]:\n",
    "        for s in [\"sgd\", \"adam\"]:\n",
    "            for pc in [0.9]:\n",
    "\n",
    "                acc_tmp, time_fit_tmp, time_pred_tmp = [], [], []\n",
    "                \n",
    "                indexes = kf.split(X_train_30, y_train_30)\n",
    "\n",
    "                for train_index, test_index in indexes:\n",
    "\n",
    "                    X_trainCV3 = X_train_std.iloc[train_index,:]\n",
    "                    y_trainCV3 = y_train.iloc[train_index]\n",
    "                    X_testCV3 = X_train_std.iloc[test_index,:]\n",
    "                    y_testCV3 = y_train.iloc[test_index]\n",
    "\n",
    "                    pca = PCA(n_components=pc)\n",
    "                    pca.fit(X_trainCV3)\n",
    "                    X_train_r = pca.transform(X_trainCV3)\n",
    "                    X_test_r = pca.transform(X_testCV3)\n",
    "   \n",
    "                    classifier3 = MLPClassifier(hidden_layer_sizes = hd, activation = a,\n",
    "                                        solver = s, batch_size = best_bs, learning_rate = \"constant\", \n",
    "                                        learning_rate_init = 0.001, max_iter = 100, shuffle = True,\n",
    "                                        random_state = 42, early_stopping = True, n_iter_no_change = 10,\n",
    "                                        validation_fraction = 0.1, verbose = False)\n",
    "                    \n",
    "                    mlp_fit_with_time(classifier3, X_train_r, y_trainCV3, time_fit_tmp)\n",
    "                    y_pred5 = mlp_predict_with_time(classifier3, X_test_r, time_pred_tmp)\n",
    "\n",
    "                    c5 = confusion_matrix(y_testCV3, y_pred5, labels=[0,1,2,3,4,5,6,7,8,9])\n",
    "                    acc_tmp.append(np.trace(c5)/sum(sum(c5)))\n",
    "\n",
    "                print(f\"{i+1}. Hd = {hd}, a = {a}, s = {s}, bs = {bs}, Average accuracy: {np.mean(acc_tmp):.6f} | Average fit time: {np.mean(time_fit_tmp):.6f}s | Average predict time: {np.mean(time_pred_tmp):.6f}s\")\n",
    "                acc.append(np.mean(acc_tmp))\n",
    "                i += 1\n",
    "\n",
    "                if np.mean(acc_tmp) > best_acc:\n",
    "                    best_acc = np.mean(acc_tmp)\n",
    "                    best_hd, best_a, best_s, best_pca = hd, a, s, pc\n",
    "            \n",
    "    print('')\n",
    "      \n",
    "print('-------------------')\n",
    "print('Best accuracy is in iteration number: ', np.argmax(acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Training on 100% training samples with PCA reduction, test on test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=best_pca)\n",
    "pca.fit(X_train_std)\n",
    "X_train_r = pca.transform(X_train_std)\n",
    "X_test_r = pca.transform(X_test_std)\n",
    "\n",
    "classifier3 = MLPClassifier(hidden_layer_sizes = best_hd, activation = best_a,\n",
    "                                    solver = best_s, batch_size = best_bs, learning_rate = \"constant\", \n",
    "                                    learning_rate_init = 0.001, max_iter = 100, shuffle = True,\n",
    "                                    random_state = 42, early_stopping = True, n_iter_no_change = 10,\n",
    "                                    validation_fraction = 0.1, verbose = False)\n",
    "\n",
    "start1 = time.time()\n",
    "classifier3.fit(X_train_r, y_train) \n",
    "fit_time = time.time() - start1\n",
    "\n",
    "start2 = time.time()\n",
    "y_pred6 = classifier3.predict(X_test_r)\n",
    "pred_time = time.time() - start2\n",
    "\n",
    "c6 = confusion_matrix(y_test, y_pred6, labels=[0,1,2,3,4,5,6,7,8,9])\n",
    "\n",
    "print(f\"Accuracy: {np.trace(c6)/sum(sum(c6)):.6f} | Average fit time: {fit_time:.6f}s | Average predict time: {pred_time:.6f}s\")\n",
    "print('-------------------')\n",
    "print('MLP parameters: hd = ', best_hd, ', a = ', best_a, ', s = ', best_s, ', bs = ', best_bs, ', pca = ', best_pca, sep='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion matrix\n",
    "print(c6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(accuracy_per_class(c6, y_test.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sensitivity_per_class(c6, y_test.unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examples of wrong classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_np = y_pred6\n",
    "print(type(y_pred6))\n",
    "\n",
    "y_test_np = y_test.to_numpy()\n",
    "print(type(y_test_np))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def differences(a,b):\n",
    "    list = []\n",
    "    for j in range(len(a)):\n",
    "        if b[j] != a[j]:\n",
    "            list = list + [j]        \n",
    "    arrayIndexes = np.asarray(list)\n",
    "    return arrayIndexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff = differences(y_pred_np, y_test_np)\n",
    "print(diff[:9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,8))\n",
    "\n",
    "for j in range(0,9):  \n",
    "    plt.subplot(3,3,j+1)    \n",
    "    arr = X_test.iloc[diff[j],:].to_numpy()\n",
    "    \n",
    "    arr = arr.reshape(28,28)\n",
    "    arr = arr.astype(np.uint8)\n",
    "    img = Image.fromarray(arr, \"L\")\n",
    "    \n",
    "    plt.imshow(img, cmap = 'gray')\n",
    "    plt.title(f\"Predicted {y_pred_np[diff[j+100]]}, Real {y_test_np[diff[j+100]]}\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "766a9d4e0fe97af3c745212a94c1e742b558cb97597ada925d7f9ef3d757d57c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
