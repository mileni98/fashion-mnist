{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "import keras\n",
    "import itertools \n",
    "import time\n",
    "\n",
    "from ipynb.fs.defs.Additional_metrics import *\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, roc_curve, precision_recall_curve\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.losses import sparse_categorical_crossentropy\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import KFold\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "train_data = pd.read_csv(\"datasets/fashion-mnist_train.csv\")\n",
    "X_train = np.array(train_data.iloc[:,1:])\n",
    "print(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trained on 30% samples of the original training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_rows, img_cols = 28, 28\n",
    "input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "train_data = pd.read_csv(\"datasets/fashion-mnist_train.csv\")\n",
    "X_train = np.array(train_data.iloc[:,1:])\n",
    "y_train = to_categorical(np.array(train_data.iloc[:,0]))\n",
    "\n",
    "X_train = X_train.reshape(X_train.shape[0], img_rows, img_cols, 1)\n",
    "X_train = X_train.astype('float32')\n",
    "\n",
    "test_data = pd.read_csv(\"datasets/fashion-mnist_test.csv\")\n",
    "X_test = np.array(test_data.iloc[:,1:])\n",
    "y_test = to_categorical(np.array(test_data.iloc[:,0]))\n",
    "\n",
    "X_test = X_test.reshape(X_test.shape[0], img_rows, img_cols, 1)\n",
    "X_test = X_test.astype('float32')\n",
    "\n",
    "X_train_std = (X_train - X_train.mean())/X_train.std()\n",
    "X_test_std = (X_test - X_test.mean())/X_test.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_30, X_test_30, y_train_30, y_test_30 = train_test_split(X_train_std, y_train, test_size=0.7, stratify=y_train, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_301, X_test_301, y_train_301, y_test_301 = train_test_split(X_train_std, y_train, test_size=0.2, stratify=y_train, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------\n",
      "Training for fold 1 ...\n",
      "Epoch 1/10\n",
      "188/188 [==============================] - 6s 33ms/step - loss: 0.4853 - accuracy: 0.8250\n",
      "Epoch 2/10\n",
      "188/188 [==============================] - 6s 32ms/step - loss: 0.3293 - accuracy: 0.8810\n",
      "Epoch 3/10\n",
      "188/188 [==============================] - 6s 32ms/step - loss: 0.2893 - accuracy: 0.8956\n",
      "Epoch 4/10\n",
      "188/188 [==============================] - 6s 32ms/step - loss: 0.2638 - accuracy: 0.9045\n",
      "Epoch 5/10\n",
      "188/188 [==============================] - 6s 32ms/step - loss: 0.2384 - accuracy: 0.9120\n",
      "Epoch 6/10\n",
      "188/188 [==============================] - 6s 32ms/step - loss: 0.2219 - accuracy: 0.9184\n",
      "Epoch 7/10\n",
      "188/188 [==============================] - 6s 32ms/step - loss: 0.2054 - accuracy: 0.9250\n",
      "Epoch 8/10\n",
      "188/188 [==============================] - 6s 33ms/step - loss: 0.1896 - accuracy: 0.9313\n",
      "Epoch 9/10\n",
      "188/188 [==============================] - 6s 33ms/step - loss: 0.1774 - accuracy: 0.9340\n",
      "Epoch 10/10\n",
      "188/188 [==============================] - 6s 33ms/step - loss: 0.1633 - accuracy: 0.9400\n",
      "Score for fold 1: loss of 0.2541258633136749; accuracy of 91.24166369438171%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 2 ...\n",
      "Epoch 1/10\n",
      "188/188 [==============================] - 6s 33ms/step - loss: 0.4794 - accuracy: 0.8299\n",
      "Epoch 2/10\n",
      "188/188 [==============================] - 6s 32ms/step - loss: 0.3356 - accuracy: 0.8805\n",
      "Epoch 3/10\n",
      "188/188 [==============================] - 6s 33ms/step - loss: 0.2930 - accuracy: 0.8947\n",
      "Epoch 4/10\n",
      "188/188 [==============================] - 6s 33ms/step - loss: 0.2701 - accuracy: 0.9009\n",
      "Epoch 5/10\n",
      "188/188 [==============================] - 6s 33ms/step - loss: 0.2479 - accuracy: 0.9085\n",
      "Epoch 6/10\n",
      "188/188 [==============================] - 6s 33ms/step - loss: 0.2288 - accuracy: 0.9166\n",
      "Epoch 7/10\n",
      "188/188 [==============================] - 6s 33ms/step - loss: 0.2150 - accuracy: 0.9211\n",
      "Epoch 8/10\n",
      "188/188 [==============================] - 6s 33ms/step - loss: 0.2013 - accuracy: 0.9252\n",
      "Epoch 9/10\n",
      "188/188 [==============================] - 6s 33ms/step - loss: 0.1891 - accuracy: 0.9304\n",
      "Epoch 10/10\n",
      "188/188 [==============================] - 6s 33ms/step - loss: 0.1768 - accuracy: 0.9341\n",
      "Score for fold 2: loss of 0.25623631477355957; accuracy of 91.00000262260437%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 3 ...\n",
      "Epoch 1/10\n",
      "188/188 [==============================] - 6s 32ms/step - loss: 0.4817 - accuracy: 0.8288\n",
      "Epoch 2/10\n",
      "188/188 [==============================] - 6s 32ms/step - loss: 0.3285 - accuracy: 0.8839\n",
      "Epoch 3/10\n",
      "188/188 [==============================] - 6s 32ms/step - loss: 0.2884 - accuracy: 0.8978\n",
      "Epoch 4/10\n",
      "188/188 [==============================] - 6s 32ms/step - loss: 0.2555 - accuracy: 0.9080\n",
      "Epoch 5/10\n",
      "188/188 [==============================] - 6s 32ms/step - loss: 0.2396 - accuracy: 0.9132\n",
      "Epoch 6/10\n",
      "188/188 [==============================] - 6s 32ms/step - loss: 0.2141 - accuracy: 0.9219\n",
      "Epoch 7/10\n",
      "188/188 [==============================] - 6s 33ms/step - loss: 0.2021 - accuracy: 0.9258\n",
      "Epoch 8/10\n",
      "188/188 [==============================] - 6s 32ms/step - loss: 0.1872 - accuracy: 0.9309\n",
      "Epoch 9/10\n",
      "188/188 [==============================] - 6s 33ms/step - loss: 0.1772 - accuracy: 0.9352\n",
      "Epoch 10/10\n",
      "188/188 [==============================] - 6s 33ms/step - loss: 0.1683 - accuracy: 0.9379\n",
      "Score for fold 3: loss of 0.2511812448501587; accuracy of 91.05833172798157%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 4 ...\n",
      "Epoch 1/10\n",
      "188/188 [==============================] - 6s 33ms/step - loss: 0.4834 - accuracy: 0.8271\n",
      "Epoch 2/10\n",
      "188/188 [==============================] - 6s 33ms/step - loss: 0.3267 - accuracy: 0.8826\n",
      "Epoch 3/10\n",
      "188/188 [==============================] - 6s 32ms/step - loss: 0.2880 - accuracy: 0.8951\n",
      "Epoch 4/10\n",
      "188/188 [==============================] - 6s 33ms/step - loss: 0.2577 - accuracy: 0.9060\n",
      "Epoch 5/10\n",
      "188/188 [==============================] - 6s 33ms/step - loss: 0.2348 - accuracy: 0.9145\n",
      "Epoch 6/10\n",
      "188/188 [==============================] - 6s 33ms/step - loss: 0.2178 - accuracy: 0.9208\n",
      "Epoch 7/10\n",
      "188/188 [==============================] - 6s 33ms/step - loss: 0.2052 - accuracy: 0.9243\n",
      "Epoch 8/10\n",
      "188/188 [==============================] - 6s 33ms/step - loss: 0.1890 - accuracy: 0.9299\n",
      "Epoch 9/10\n",
      "188/188 [==============================] - 6s 32ms/step - loss: 0.1776 - accuracy: 0.9341\n",
      "Epoch 10/10\n",
      "188/188 [==============================] - 6s 33ms/step - loss: 0.1657 - accuracy: 0.9386\n",
      "Score for fold 4: loss of 0.24466632306575775; accuracy of 91.24166369438171%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 5 ...\n",
      "Epoch 1/10\n",
      "188/188 [==============================] - 6s 33ms/step - loss: 0.5024 - accuracy: 0.8189\n",
      "Epoch 2/10\n",
      "188/188 [==============================] - 6s 33ms/step - loss: 0.3354 - accuracy: 0.8798\n",
      "Epoch 3/10\n",
      "188/188 [==============================] - 6s 33ms/step - loss: 0.2945 - accuracy: 0.8935\n",
      "Epoch 4/10\n",
      "188/188 [==============================] - 6s 32ms/step - loss: 0.2675 - accuracy: 0.9020\n",
      "Epoch 5/10\n",
      "188/188 [==============================] - 6s 32ms/step - loss: 0.2452 - accuracy: 0.9115\n",
      "Epoch 6/10\n",
      "188/188 [==============================] - 6s 32ms/step - loss: 0.2234 - accuracy: 0.9179\n",
      "Epoch 7/10\n",
      "188/188 [==============================] - 6s 32ms/step - loss: 0.2109 - accuracy: 0.9227\n",
      "Epoch 8/10\n",
      "188/188 [==============================] - 6s 33ms/step - loss: 0.1967 - accuracy: 0.9274\n",
      "Epoch 9/10\n",
      "188/188 [==============================] - 6s 33ms/step - loss: 0.1831 - accuracy: 0.9327\n",
      "Epoch 10/10\n",
      "188/188 [==============================] - 6s 33ms/step - loss: 0.1723 - accuracy: 0.9355\n",
      "Score for fold 5: loss of 0.2452380508184433; accuracy of 91.41666889190674%\n",
      "\n",
      "Average execution time: 62.59512758\n"
     ]
    }
   ],
   "source": [
    "acc_per_fold = []\n",
    "loss_per_fold = []\n",
    "\n",
    "inputs = np.concatenate((X_train_301, X_test_301), axis=0)\n",
    "targets = np.concatenate((y_train_301, y_test_301), axis=0)\n",
    "\n",
    "kfold = KFold(n_splits=5, shuffle=True)\n",
    "\n",
    "fold_no = 1\n",
    "\n",
    "time_tmp = []\n",
    "\n",
    "for train, test in kfold.split(inputs, targets):\n",
    "\n",
    "    cnn1 = Sequential()\n",
    "    cnn1.add(Conv2D(32, kernel_size=(5,5), activation='relu', input_shape=input_shape))\n",
    "    cnn1.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    cnn1.add(Dropout(0.2))\n",
    "\n",
    "    cnn1.add(Flatten())\n",
    "\n",
    "    cnn1.add(Dense(128, activation='relu'))\n",
    "    cnn1.add(Dense(10, activation='softmax'))\n",
    "\n",
    "    cnn1.compile(loss=keras.losses.categorical_crossentropy,\n",
    "                     optimizer=keras.optimizers.Adam(),\n",
    "                     metrics=['accuracy'])\n",
    "\n",
    "    print('------------------------------------------------------------------------')\n",
    "    print(f'Training for fold {fold_no} ...')\n",
    "\n",
    "    start = time.time()\n",
    "\n",
    "    history = cnn1.fit(inputs[train], targets[train],\n",
    "                  batch_size=256,\n",
    "                  epochs=10,\n",
    "                  verbose=1)\n",
    "\n",
    "    scores = cnn1.evaluate(inputs[test], targets[test], verbose=0)\n",
    "\n",
    "    end = time.time()\n",
    "\n",
    "    time_tmp.append(end-start)\n",
    "\n",
    "    print(f'Score for fold {fold_no}: {cnn1.metrics_names[0]} of {scores[0]}; {cnn1.metrics_names[1]} of {scores[1]*100}%')\n",
    "    acc_per_fold.append(scores[1] * 100)\n",
    "    loss_per_fold.append(scores[0])\n",
    "\n",
    "    # Increase fold number\n",
    "    fold_no = fold_no + 1\n",
    "\n",
    "print('')\n",
    "print('Average execution time: ', round(np.mean(time_tmp),8), sep='')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------\n",
      "Score per fold\n",
      "------------------------------------------------------------------------\n",
      "> Fold 1 - Loss: 0.2541258633136749 - Accuracy: 91.24166369438171%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 2 - Loss: 0.25623631477355957 - Accuracy: 91.00000262260437%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 3 - Loss: 0.2511812448501587 - Accuracy: 91.05833172798157%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 4 - Loss: 0.24466632306575775 - Accuracy: 91.24166369438171%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 5 - Loss: 0.2452380508184433 - Accuracy: 91.41666889190674%\n",
      "------------------------------------------------------------------------\n",
      "Average scores for all folds:\n",
      "> Accuracy: 91.19166612625122 (+- 0.14841746432457012)\n",
      "> Loss: 0.25028955936431885\n",
      "------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print('------------------------------------------------------------------------')\n",
    "print('Score per fold')\n",
    "for i in range(0, len(acc_per_fold)):\n",
    "  print('------------------------------------------------------------------------')\n",
    "  print(f'> Fold {i+1} - Loss: {loss_per_fold[i]} - Accuracy: {acc_per_fold[i]}%')\n",
    "print('------------------------------------------------------------------------')\n",
    "print('Average scores for all folds:')\n",
    "print(f'> Accuracy: {np.mean(acc_per_fold)} (+- {np.std(acc_per_fold)})')\n",
    "print(f'> Loss: {np.mean(loss_per_fold)}')\n",
    "print('------------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training on 30% training samples, test on test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "71/71 [==============================] - 3s 32ms/step - loss: 0.6299 - accuracy: 0.7805\n",
      "Epoch 2/10\n",
      "71/71 [==============================] - 2s 32ms/step - loss: 0.3865 - accuracy: 0.8653\n",
      "Epoch 3/10\n",
      "71/71 [==============================] - 2s 32ms/step - loss: 0.3375 - accuracy: 0.8789\n",
      "Epoch 4/10\n",
      "71/71 [==============================] - 2s 33ms/step - loss: 0.3034 - accuracy: 0.8927\n",
      "Epoch 5/10\n",
      "71/71 [==============================] - 2s 33ms/step - loss: 0.2743 - accuracy: 0.9039\n",
      "Epoch 6/10\n",
      "71/71 [==============================] - 2s 33ms/step - loss: 0.2506 - accuracy: 0.9085\n",
      "Epoch 7/10\n",
      "71/71 [==============================] - 2s 33ms/step - loss: 0.2427 - accuracy: 0.9129\n",
      "Epoch 8/10\n",
      "71/71 [==============================] - 2s 33ms/step - loss: 0.2231 - accuracy: 0.9173\n",
      "Epoch 9/10\n",
      "71/71 [==============================] - 2s 33ms/step - loss: 0.2090 - accuracy: 0.9227\n",
      "Epoch 10/10\n",
      "71/71 [==============================] - 2s 32ms/step - loss: 0.1926 - accuracy: 0.9315\n",
      "Score for fold 6: loss of 0.30254828929901123; accuracy of 89.17999863624573%\n",
      "\n",
      "Average execution time: 24.60630941\n"
     ]
    }
   ],
   "source": [
    "acc_per_fold = []\n",
    "loss_per_fold = []\n",
    "\n",
    "time_tmp = []\n",
    "\n",
    "\n",
    "cnn1 = Sequential()\n",
    "cnn1.add(Conv2D(32, kernel_size=(5,5), activation='relu', input_shape=input_shape))\n",
    "cnn1.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "cnn1.add(Dropout(0.2))\n",
    "\n",
    "cnn1.add(Flatten())\n",
    "\n",
    "cnn1.add(Dense(128, activation='relu'))\n",
    "cnn1.add(Dense(10, activation='softmax'))\n",
    "\n",
    "cnn1.compile(loss=keras.losses.categorical_crossentropy,\n",
    "                     optimizer=keras.optimizers.Adam(),\n",
    "                     metrics=['accuracy'])\n",
    "\n",
    "start = time.time()\n",
    "history = cnn1.fit(X_train_30, y_train_30,\n",
    "                  batch_size=256,\n",
    "                  epochs=10,\n",
    "                  verbose=1)\n",
    "\n",
    "scores = cnn1.evaluate(X_test_std, y_test, verbose=0)\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "time_tmp.append(end-start)\n",
    "\n",
    "print(f'Score for fold {fold_no}: {cnn1.metrics_names[0]} of {scores[0]}; {cnn1.metrics_names[1]} of {scores[1]*100}%')\n",
    "acc_per_fold.append(scores[1] * 100)\n",
    "loss_per_fold.append(scores[0])\n",
    "\n",
    "\n",
    "print('')\n",
    "print('Average execution time: ', round(np.mean(time_tmp),8), sep='')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trained on 100% samples of the original training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_rows, img_cols = 28, 28\n",
    "input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "train_data = pd.read_csv(\"datasets/fashion-mnist_train.csv\")\n",
    "X_train = np.array(train_data.iloc[:,1:])\n",
    "y_train = to_categorical(np.array(train_data.iloc[:,0]))\n",
    "\n",
    "X_train = X_train.reshape(X_train.shape[0], img_rows, img_cols, 1)\n",
    "X_train = X_train.astype('float32')\n",
    "\n",
    "test_data = pd.read_csv(\"datasets/fashion-mnist_test.csv\")\n",
    "X_test = np.array(test_data.iloc[:,1:])\n",
    "y_test = to_categorical(np.array(test_data.iloc[:,0]))\n",
    "\n",
    "X_test = X_test.reshape(X_test.shape[0], img_rows, img_cols, 1)\n",
    "X_test = X_test.astype('float32')\n",
    "\n",
    "X_train_std = (X_train - X_train.mean())/X_train.std()\n",
    "X_test_std = (X_test - X_test.mean())/X_test.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_1, X_test_1, y_train_1, y_test_1 = train_test_split(X_train_std, y_train, test_size=0.2, stratify=y_train, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------\n",
      "Training for fold 1 ...\n",
      "Epoch 1/10\n",
      "188/188 [==============================] - 7s 33ms/step - loss: 0.4860 - accuracy: 0.8263\n",
      "Epoch 2/10\n",
      "188/188 [==============================] - 6s 33ms/step - loss: 0.3330 - accuracy: 0.8809\n",
      "Epoch 3/10\n",
      "188/188 [==============================] - 6s 33ms/step - loss: 0.2912 - accuracy: 0.8951\n",
      "Epoch 4/10\n",
      "188/188 [==============================] - 6s 33ms/step - loss: 0.2618 - accuracy: 0.9041\n",
      "Epoch 5/10\n",
      "188/188 [==============================] - 6s 33ms/step - loss: 0.2422 - accuracy: 0.9099\n",
      "Epoch 6/10\n",
      "188/188 [==============================] - 6s 33ms/step - loss: 0.2252 - accuracy: 0.9165\n",
      "Epoch 7/10\n",
      "188/188 [==============================] - 6s 33ms/step - loss: 0.2084 - accuracy: 0.9239\n",
      "Epoch 8/10\n",
      "188/188 [==============================] - 6s 33ms/step - loss: 0.1959 - accuracy: 0.9270\n",
      "Epoch 9/10\n",
      "188/188 [==============================] - 6s 33ms/step - loss: 0.1774 - accuracy: 0.9336\n",
      "Epoch 10/10\n",
      "188/188 [==============================] - 6s 32ms/step - loss: 0.1657 - accuracy: 0.9382\n",
      "Score for fold 1: loss of 0.24414268136024475; accuracy of 91.49166941642761%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 2 ...\n",
      "Epoch 1/10\n",
      "188/188 [==============================] - 6s 33ms/step - loss: 0.4794 - accuracy: 0.8300\n",
      "Epoch 2/10\n",
      "188/188 [==============================] - 6s 32ms/step - loss: 0.3312 - accuracy: 0.8820\n",
      "Epoch 3/10\n",
      "188/188 [==============================] - 6s 33ms/step - loss: 0.2903 - accuracy: 0.8955\n",
      "Epoch 4/10\n",
      "188/188 [==============================] - 6s 33ms/step - loss: 0.2640 - accuracy: 0.9046\n",
      "Epoch 5/10\n",
      "188/188 [==============================] - 6s 33ms/step - loss: 0.2395 - accuracy: 0.9133\n",
      "Epoch 6/10\n",
      "188/188 [==============================] - 6s 33ms/step - loss: 0.2205 - accuracy: 0.9195\n",
      "Epoch 7/10\n",
      "188/188 [==============================] - 6s 32ms/step - loss: 0.2080 - accuracy: 0.9233\n",
      "Epoch 8/10\n",
      "188/188 [==============================] - 6s 32ms/step - loss: 0.1941 - accuracy: 0.9288\n",
      "Epoch 9/10\n",
      "188/188 [==============================] - 6s 32ms/step - loss: 0.1763 - accuracy: 0.9358\n",
      "Epoch 10/10\n",
      "188/188 [==============================] - 6s 32ms/step - loss: 0.1662 - accuracy: 0.9387\n",
      "Score for fold 2: loss of 0.23866590857505798; accuracy of 91.44166707992554%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 3 ...\n",
      "Epoch 1/10\n",
      "188/188 [==============================] - 7s 33ms/step - loss: 0.4875 - accuracy: 0.8269\n",
      "Epoch 2/10\n",
      "188/188 [==============================] - 6s 33ms/step - loss: 0.3270 - accuracy: 0.8829\n",
      "Epoch 3/10\n",
      "188/188 [==============================] - 6s 33ms/step - loss: 0.2882 - accuracy: 0.8959\n",
      "Epoch 4/10\n",
      "188/188 [==============================] - 6s 33ms/step - loss: 0.2624 - accuracy: 0.9050\n",
      "Epoch 5/10\n",
      "188/188 [==============================] - 6s 33ms/step - loss: 0.2366 - accuracy: 0.9147\n",
      "Epoch 6/10\n",
      "188/188 [==============================] - 6s 33ms/step - loss: 0.2239 - accuracy: 0.9168\n",
      "Epoch 7/10\n",
      "188/188 [==============================] - 6s 33ms/step - loss: 0.2076 - accuracy: 0.9227\n",
      "Epoch 8/10\n",
      "188/188 [==============================] - 6s 33ms/step - loss: 0.1898 - accuracy: 0.9294\n",
      "Epoch 9/10\n",
      "188/188 [==============================] - 6s 33ms/step - loss: 0.1832 - accuracy: 0.9317\n",
      "Epoch 10/10\n",
      "188/188 [==============================] - 6s 33ms/step - loss: 0.1703 - accuracy: 0.9367\n",
      "Score for fold 3: loss of 0.24370573461055756; accuracy of 91.14999771118164%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 4 ...\n",
      "Epoch 1/10\n",
      "188/188 [==============================] - 7s 33ms/step - loss: 0.4910 - accuracy: 0.8261\n",
      "Epoch 2/10\n",
      "188/188 [==============================] - 6s 33ms/step - loss: 0.3361 - accuracy: 0.8795\n",
      "Epoch 3/10\n",
      "188/188 [==============================] - 6s 33ms/step - loss: 0.2901 - accuracy: 0.8953\n",
      "Epoch 4/10\n",
      "188/188 [==============================] - 6s 33ms/step - loss: 0.2634 - accuracy: 0.9050\n",
      "Epoch 5/10\n",
      "188/188 [==============================] - 6s 33ms/step - loss: 0.2425 - accuracy: 0.9122\n",
      "Epoch 6/10\n",
      "188/188 [==============================] - 6s 33ms/step - loss: 0.2259 - accuracy: 0.9176\n",
      "Epoch 7/10\n",
      "188/188 [==============================] - 6s 33ms/step - loss: 0.2036 - accuracy: 0.9257\n",
      "Epoch 8/10\n",
      "188/188 [==============================] - 6s 33ms/step - loss: 0.1932 - accuracy: 0.9280\n",
      "Epoch 9/10\n",
      "188/188 [==============================] - 6s 33ms/step - loss: 0.1811 - accuracy: 0.9329\n",
      "Epoch 10/10\n",
      "188/188 [==============================] - 6s 33ms/step - loss: 0.1699 - accuracy: 0.9374\n",
      "Score for fold 4: loss of 0.23662619292736053; accuracy of 91.8416678905487%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 5 ...\n",
      "Epoch 1/10\n",
      "188/188 [==============================] - 7s 33ms/step - loss: 0.4826 - accuracy: 0.8266\n",
      "Epoch 2/10\n",
      "188/188 [==============================] - 6s 32ms/step - loss: 0.3281 - accuracy: 0.8829\n",
      "Epoch 3/10\n",
      "188/188 [==============================] - 6s 32ms/step - loss: 0.2855 - accuracy: 0.8977\n",
      "Epoch 4/10\n",
      "188/188 [==============================] - 6s 32ms/step - loss: 0.2599 - accuracy: 0.9065\n",
      "Epoch 5/10\n",
      "188/188 [==============================] - 6s 32ms/step - loss: 0.2400 - accuracy: 0.9129\n",
      "Epoch 6/10\n",
      "188/188 [==============================] - 6s 32ms/step - loss: 0.2208 - accuracy: 0.9188\n",
      "Epoch 7/10\n",
      "188/188 [==============================] - 6s 32ms/step - loss: 0.2076 - accuracy: 0.9254\n",
      "Epoch 8/10\n",
      "188/188 [==============================] - 6s 32ms/step - loss: 0.1898 - accuracy: 0.9303\n",
      "Epoch 9/10\n",
      "188/188 [==============================] - 6s 32ms/step - loss: 0.1774 - accuracy: 0.9349\n",
      "Epoch 10/10\n",
      "188/188 [==============================] - 6s 32ms/step - loss: 0.1650 - accuracy: 0.9386\n",
      "Score for fold 5: loss of 0.2500353455543518; accuracy of 91.09166860580444%\n",
      "\n",
      "Average execution time: 63.07992783\n"
     ]
    }
   ],
   "source": [
    "acc_per_fold = []\n",
    "loss_per_fold = []\n",
    "\n",
    "inputs = np.concatenate((X_train_1, X_test_1), axis=0)\n",
    "targets = np.concatenate((y_train_1, y_test_1), axis=0)\n",
    "\n",
    "kfold = KFold(n_splits=5, shuffle=True)\n",
    "\n",
    "fold_no = 1\n",
    "\n",
    "time_tmp = []\n",
    "\n",
    "for train, test in kfold.split(inputs, targets):\n",
    "\n",
    "    cnn1 = Sequential()\n",
    "    cnn1.add(Conv2D(32, kernel_size=(5,5), activation='relu', input_shape=input_shape))\n",
    "    cnn1.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    cnn1.add(Dropout(0.2))\n",
    "\n",
    "    cnn1.add(Flatten())\n",
    "\n",
    "    cnn1.add(Dense(128, activation='relu'))\n",
    "    cnn1.add(Dense(10, activation='softmax'))\n",
    "\n",
    "    cnn1.compile(loss=keras.losses.categorical_crossentropy,\n",
    "                     optimizer=keras.optimizers.Adam(),\n",
    "                     metrics=['accuracy'])\n",
    "\n",
    "    print('------------------------------------------------------------------------')\n",
    "    print(f'Training for fold {fold_no} ...')\n",
    "\n",
    "    start = time.time()\n",
    "\n",
    "    history = cnn1.fit(inputs[train], targets[train],\n",
    "                  batch_size=256,\n",
    "                  epochs=10,\n",
    "                  verbose=1)\n",
    "\n",
    "    scores = cnn1.evaluate(inputs[test], targets[test], verbose=0)\n",
    "\n",
    "    end = time.time()\n",
    "\n",
    "    time_tmp.append(end-start)\n",
    "\n",
    "    print(f'Score for fold {fold_no}: {cnn1.metrics_names[0]} of {scores[0]}; {cnn1.metrics_names[1]} of {scores[1]*100}%')\n",
    "    acc_per_fold.append(scores[1] * 100)\n",
    "    loss_per_fold.append(scores[0])\n",
    "\n",
    "    # Increase fold number\n",
    "    fold_no = fold_no + 1\n",
    "\n",
    "print('')\n",
    "print('Average execution time: ', round(np.mean(time_tmp),8), sep='')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------\n",
      "Score per fold\n",
      "------------------------------------------------------------------------\n",
      "> Fold 1 - Loss: 0.24414268136024475 - Accuracy: 91.49166941642761%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 2 - Loss: 0.23866590857505798 - Accuracy: 91.44166707992554%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 3 - Loss: 0.24370573461055756 - Accuracy: 91.14999771118164%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 4 - Loss: 0.23662619292736053 - Accuracy: 91.8416678905487%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 5 - Loss: 0.2500353455543518 - Accuracy: 91.09166860580444%\n",
      "------------------------------------------------------------------------\n",
      "Average scores for all folds:\n",
      "> Accuracy: 91.40333414077759 (+- 0.26934133124599136)\n",
      "> Loss: 0.24263517260551454\n",
      "------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print('------------------------------------------------------------------------')\n",
    "print('Score per fold')\n",
    "for i in range(0, len(acc_per_fold)):\n",
    "  print('------------------------------------------------------------------------')\n",
    "  print(f'> Fold {i+1} - Loss: {loss_per_fold[i]} - Accuracy: {acc_per_fold[i]}%')\n",
    "print('------------------------------------------------------------------------')\n",
    "print('Average scores for all folds:')\n",
    "print(f'> Accuracy: {np.mean(acc_per_fold)} (+- {np.std(acc_per_fold)})')\n",
    "print(f'> Loss: {np.mean(loss_per_fold)}')\n",
    "print('------------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "235/235 [==============================] - 8s 32ms/step - loss: 0.4573 - accuracy: 0.8357\n",
      "Epoch 2/10\n",
      "235/235 [==============================] - 8s 32ms/step - loss: 0.3149 - accuracy: 0.8876\n",
      "Epoch 3/10\n",
      "235/235 [==============================] - 8s 33ms/step - loss: 0.2714 - accuracy: 0.9017\n",
      "Epoch 4/10\n",
      "235/235 [==============================] - 8s 33ms/step - loss: 0.2468 - accuracy: 0.9089\n",
      "Epoch 5/10\n",
      "235/235 [==============================] - 8s 33ms/step - loss: 0.2247 - accuracy: 0.9174\n",
      "Epoch 6/10\n",
      "235/235 [==============================] - 8s 33ms/step - loss: 0.2050 - accuracy: 0.9245\n",
      "Epoch 7/10\n",
      "235/235 [==============================] - 8s 32ms/step - loss: 0.1905 - accuracy: 0.9288\n",
      "Epoch 8/10\n",
      "235/235 [==============================] - 8s 32ms/step - loss: 0.1788 - accuracy: 0.9338\n",
      "Epoch 9/10\n",
      "235/235 [==============================] - 8s 33ms/step - loss: 0.1656 - accuracy: 0.9388\n",
      "Epoch 10/10\n",
      "235/235 [==============================] - 8s 33ms/step - loss: 0.1555 - accuracy: 0.9428\n",
      "Score for fold 6: loss of 0.23493218421936035; accuracy of 91.39999747276306%\n",
      "\n",
      "Average execution time: 77.93272161\n"
     ]
    }
   ],
   "source": [
    "acc_per_fold = []\n",
    "loss_per_fold = []\n",
    "\n",
    "time_tmp = []\n",
    "\n",
    "\n",
    "cnn1 = Sequential()\n",
    "cnn1.add(Conv2D(32, kernel_size=(5,5), activation='relu', input_shape=input_shape))\n",
    "cnn1.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "cnn1.add(Dropout(0.2))\n",
    "\n",
    "cnn1.add(Flatten())\n",
    "\n",
    "cnn1.add(Dense(128, activation='relu'))\n",
    "cnn1.add(Dense(10, activation='softmax'))\n",
    "\n",
    "cnn1.compile(loss=keras.losses.categorical_crossentropy,\n",
    "                     optimizer=keras.optimizers.Adam(),\n",
    "                     metrics=['accuracy'])\n",
    "\n",
    "start = time.time()\n",
    "history = cnn1.fit(X_train_std, y_train,\n",
    "                  batch_size=256,\n",
    "                  epochs=10,\n",
    "                  verbose=1)\n",
    "\n",
    "scores = cnn1.evaluate(X_test_std, y_test, verbose=0)\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "time_tmp.append(end-start)\n",
    "\n",
    "print(f'Score for fold {fold_no}: {cnn1.metrics_names[0]} of {scores[0]}; {cnn1.metrics_names[1]} of {scores[1]*100}%')\n",
    "acc_per_fold.append(scores[1] * 100)\n",
    "loss_per_fold.append(scores[0])\n",
    "\n",
    "\n",
    "print('')\n",
    "print('Average execution time: ', round(np.mean(time_tmp),8), sep='')    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trained on 100% samples with PCA reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_rows, img_cols = 28, 28\n",
    "input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "train_data = pd.read_csv(\"datasets/fashion-mnist_train.csv\")\n",
    "X_train = np.array(train_data.iloc[:,1:])\n",
    "y_train = to_categorical(np.array(train_data.iloc[:,0]))\n",
    "\n",
    "X_train = X_train.reshape(X_train.shape[0], img_rows, img_cols, 1)\n",
    "X_train = X_train.astype('float32')\n",
    "\n",
    "test_data = pd.read_csv(\"datasets/fashion-mnist_test.csv\")\n",
    "X_test = np.array(test_data.iloc[:,1:])\n",
    "y_test = to_categorical(np.array(test_data.iloc[:,0]))\n",
    "\n",
    "X_test = X_test.reshape(X_test.shape[0], img_rows, img_cols, 1)\n",
    "X_test = X_test.astype('float32')\n",
    "\n",
    "X_train_std = (X_train - X_train.mean())/X_train.std()\n",
    "X_test_std = (X_test - X_test.mean())/X_test.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=pc)\n",
    "                    pca.fit(X_trainCV3)\n",
    "                    X_train_r = pca.transform(X_trainCV3)\n",
    "                    X_test_r = pca.transform(X_testCV3)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "766a9d4e0fe97af3c745212a94c1e742b558cb97597ada925d7f9ef3d757d57c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
